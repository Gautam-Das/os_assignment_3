## Operating Systems Assignment 3 - Concurrency

* Authors: Gautam Das, Cuinn Kemp, Rylan Ford
* Group: 132

## Overview

This project implements a multi-threaded version of the merge sort
algorithm in C, otherwise known as parallel merge sort. This work has
been undertaken to demonstrate inter-thread synchronisation using the
pthread library. 

## Manifest

```
Makefile # Useage: make, make clean
mergesort.c # Contains core functionality of merge sort
mergesort.h # Function definitions for mergesort.c
test-mergesort.c # Contains functionality for testing mergesort
README
```

## Building the project

The test-mergesort script can be run through the following sequence:

```
Make
./test-mergesort <input_size> <cutoff_level> <seed>
```

To remove make files, run:

```
Make clean
```

## Features and usage

This program demonstrates the time speedup when running parallel merge sort
with increasing cutoff levels. In each cutoff level, the array is split so
that both segments can be passed to individual threads. The uses specifies 
the maximum number of levels in which this occurs. A significant incremental
speedup can be observed when increasing the cutoff level from 0 (i.e. serial
merge sort) to 5. Beyond this point, the cutoff threshold is no longer the
bottle neck. 

To observe this pattern, the following sequence of inputs can be tested:

```
./test_mergesort 100000000 0 1234
./test_mergesort 100000000 1 1234
./test_mergesort 100000000 2 1234
./test_mergesort 100000000 3 1234
./test_mergesort 100000000 4 1234
./test_mergesort 100000000 5 1234
./test_mergesort 100000000 6 1234
```

## Testing

Testing was conducted according to assignment specification using an input
size of 100,000,000 and variable cutoff levels in the range 0-8. Multiple 
random seeds were also used throughout testing to validate results. The
test-mergesort.c script contains functionality to ensure that arrays are 
correctly sorted meaning testing was conducted primarily to verify that
increasing the cutoff level (i.e. using multiprocessing) did result in an
expected speedup by at least a factor of 2. 

## Reflection and Self Assessment
The main issue we had with the development was dealing with extreme cutoffs. Our initial implementation would fail for cutoff > 14. We came to the conclusion that this was due to threads starving just due to the sheer number of them. For example, a cutoff of 14, causes 2^14 (16384) threads to spawn, which our machines could not handle. To fix these we tried using a semaphore to limit the number of threads being created. But that didn't since a thread could spawn child threads, that won't run due to a semaphore blocking them, leading to deadlock. So, to address the issues, we limited the cutoff to 13 levels, leading to 8192 threads, which fixed the starvation issue. Later research showed that on some systems a process isn't alloweed to have more than 2-4000 threads, which was the reason for crashing on some devices.

The project was generally quite easy without any major issues except for the one mentioned above. The development and testing process was pretty good as we wrote a python script for testing extreme edge cases along with analysing the performance.

## Sources Used
